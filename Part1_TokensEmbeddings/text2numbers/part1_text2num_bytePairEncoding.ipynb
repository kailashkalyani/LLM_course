{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q8_-VKZNDmzB"
      },
      "source": [
        "|<h2>Course:</h2>|<h1><a href=\"https://udemy.com/course/dullms_x/?couponCode=202508\" target=\"_blank\">A deep understanding of AI language model mechanisms</a></h1>|\n",
        "|-|:-:|\n",
        "|<h2>Part 1:</h2>|<h1>Tokenizations and embeddingss<h1>|\n",
        "|<h2>Section:</h2>|<h1>Words to tokens to numbers<h1>|\n",
        "|<h2>Lecture:</h2>|<h1><b>Byte-pair encoding<b></h1>|\n",
        "\n",
        "<br>\n",
        "\n",
        "<h5><b>Teacher:</b> Mike X Cohen, <a href=\"https://sincxpress.com\" target=\"_blank\">sincxpress.com</a></h5>\n",
        "<h5><b>Course URL:</b> <a href=\"https://udemy.com/course/dullms_x/?couponCode=202508\" target=\"_blank\">udemy.com/course/dullms_x/?couponCode=202508</a></h5>\n",
        "<i>Using the code without the course may lead to confusion or errors.</i>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "APFQtXa0brAf"
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TrCWDXUdTS_N"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bRwQVVLT6ZNP"
      },
      "source": [
        "# Initialize the vocabulary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "6M7HN5nLTmaq"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\" \" appears 7 times.\n",
            "\"a\" appears 1 times.\n",
            "\"e\" appears 5 times.\n",
            "\"g\" appears 5 times.\n",
            "\"h\" appears 4 times.\n",
            "\"i\" appears 3 times.\n",
            "\"k\" appears 2 times.\n",
            "\"l\" appears 5 times.\n",
            "\"n\" appears 1 times.\n",
            "\"o\" appears 2 times.\n",
            "\"r\" appears 2 times.\n",
            "\"s\" appears 2 times.\n",
            "\"t\" appears 1 times.\n",
            "\"u\" appears 3 times.\n",
            "\"v\" appears 2 times.\n",
            "\"y\" appears 1 times.\n"
          ]
        }
      ],
      "source": [
        "# some text with lots of repetitions\n",
        "text = 'like liker love lovely hug hugs hugging hearts'\n",
        "\n",
        "chars = list(set(text))\n",
        "chars.sort() # initial vocab is sorted\n",
        "\n",
        "for l in chars:\n",
        "  print(f'\"{l}\" appears {text.count(l)} times.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "mXFIcoLk7Q8F"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{' ': 0,\n",
              " 'a': 1,\n",
              " 'e': 2,\n",
              " 'g': 3,\n",
              " 'h': 4,\n",
              " 'i': 5,\n",
              " 'k': 6,\n",
              " 'l': 7,\n",
              " 'n': 8,\n",
              " 'o': 9,\n",
              " 'r': 10,\n",
              " 's': 11,\n",
              " 't': 12,\n",
              " 'u': 13,\n",
              " 'v': 14,\n",
              " 'y': 15}"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# make a vocabulary\n",
        "vocab = { word:i for i,word in enumerate(chars) }\n",
        "vocab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "k70QKgFkBCr2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "like liker love lovely hug hugs hugging hearts\n",
            "['l', 'i', 'k', 'e', ' ', 'l', 'i', 'k', 'e', 'r', ' ', 'l', 'o', 'v', 'e', ' ', 'l', 'o', 'v', 'e', 'l', 'y', ' ', 'h', 'u', 'g', ' ', 'h', 'u', 'g', 's', ' ', 'h', 'u', 'g', 'g', 'i', 'n', 'g', ' ', 'h', 'e', 'a', 'r', 't', 's']\n"
          ]
        }
      ],
      "source": [
        "# the text needs to be a list, not a string\n",
        "# each element in the list is a token\n",
        "origtext = list(text)\n",
        "print(text)\n",
        "print(origtext)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4NW4pLnVUgcd"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K_wH9S9WUgZF"
      },
      "source": [
        "# Find character pairs and merge the most frequent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "porxIPE4cqrZ"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'li': 2,\n",
              " 'ik': 2,\n",
              " 'ke': 2,\n",
              " 'e ': 2,\n",
              " ' l': 3,\n",
              " 'er': 1,\n",
              " 'r ': 1,\n",
              " 'lo': 2,\n",
              " 'ov': 2,\n",
              " 've': 2,\n",
              " 'el': 1,\n",
              " 'ly': 1,\n",
              " 'y ': 1,\n",
              " ' h': 4,\n",
              " 'hu': 3,\n",
              " 'ug': 3,\n",
              " 'g ': 2,\n",
              " 'gs': 1,\n",
              " 's ': 1,\n",
              " 'gg': 1,\n",
              " 'gi': 1,\n",
              " 'in': 1,\n",
              " 'ng': 1,\n",
              " 'he': 1,\n",
              " 'ea': 1,\n",
              " 'ar': 1,\n",
              " 'rt': 1,\n",
              " 'ts': 1}"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "token_pairs = dict()\n",
        "\n",
        "# loop over tokens\n",
        "for i in range(len(origtext)-1):\n",
        "\n",
        "  # create a pair\n",
        "  pair = origtext[i] + origtext[i+1]\n",
        "\n",
        "  # increase pair frequencies\n",
        "  if pair in token_pairs:\n",
        "    token_pairs[pair] += 1\n",
        "  else:\n",
        "    token_pairs[pair] = 1\n",
        "\n",
        "token_pairs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "uFaRRbskcqn-"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The most frequent character pair is \" h\" with 4 appearances\n"
          ]
        }
      ],
      "source": [
        "# find the most frequent pair\n",
        "mostFreqPair_idx = np.argmax(list(token_pairs.values()))\n",
        "mostFreqPair_char = list(token_pairs.keys())[mostFreqPair_idx]\n",
        "print(f'The most frequent character pair is \"{mostFreqPair_char}\" with {list(token_pairs.values())[mostFreqPair_idx]} appearances')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "RWWoz2T-FWcE"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{' ': 0,\n",
              " 'a': 1,\n",
              " 'e': 2,\n",
              " 'g': 3,\n",
              " 'h': 4,\n",
              " 'i': 5,\n",
              " 'k': 6,\n",
              " 'l': 7,\n",
              " 'n': 8,\n",
              " 'o': 9,\n",
              " 'r': 10,\n",
              " 's': 11,\n",
              " 't': 12,\n",
              " 'u': 13,\n",
              " 'v': 14,\n",
              " 'y': 15,\n",
              " ' h': 16}"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# update the vocab\n",
        "vocab[mostFreqPair_char] = max(vocab.values())+1\n",
        "vocab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "md3EG369FgmL"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "um8UTajPFght"
      },
      "source": [
        "# Replace the token pair with one token"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "9C4p87b66hMr"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "added \" h\"\n",
            "added \" h\"\n",
            "added \" h\"\n",
            "added \" h\"\n",
            "\n",
            "\n",
            "Original text: ['l', 'i', 'k', 'e', ' ', 'l', 'i', 'k', 'e', 'r', ' ', 'l', 'o', 'v', 'e', ' ', 'l', 'o', 'v', 'e', 'l', 'y', ' ', 'h', 'u', 'g', ' ', 'h', 'u', 'g', 's', ' ', 'h', 'u', 'g', 'g', 'i', 'n', 'g', ' ', 'h', 'e', 'a', 'r', 't', 's']\n",
            "Updated text:  ['l', 'i', 'k', 'e', ' ', 'l', 'i', 'k', 'e', 'r', ' ', 'l', 'o', 'v', 'e', ' ', 'l', 'o', 'v', 'e', 'l', 'y', ' h', 'u', 'g', ' h', 'u', 'g', 's', ' h', 'u', 'g', 'g', 'i', 'n', 'g', ' h', 'e', 'a', 'r', 't']\n",
            "\n",
            "\n",
            "Original text had 46 tokens; new text has 41 tokens.\n"
          ]
        }
      ],
      "source": [
        "# initialize a new text list\n",
        "newtext = []\n",
        "\n",
        "# loop through the list\n",
        "i = 0\n",
        "while i<(len(origtext)-1):\n",
        "\n",
        "  # test whether the pair of this and the following elements match the newly-created pair\n",
        "  if (origtext[i]+origtext[i+1]) == mostFreqPair_char:\n",
        "\n",
        "    # append to the new version of the text\n",
        "    newtext.append(mostFreqPair_char)\n",
        "    print(f'added \"{mostFreqPair_char}\"')\n",
        "\n",
        "    # skip the next character\n",
        "    i += 2\n",
        "\n",
        "  # this isn't a merged pair, so add this token to the list\n",
        "  else:\n",
        "    newtext.append(origtext[i])\n",
        "\n",
        "    # move to the next character\n",
        "    i += 1\n",
        "\n",
        "\n",
        "print('\\n')\n",
        "print(f'Original text: {origtext}')\n",
        "print(f'Updated text:  {newtext}')\n",
        "\n",
        "print(f'\\n\\nOriginal text had {len(origtext)} tokens; new text has {len(newtext)} tokens.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T7oJ4dgs6hPe"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "axWcmSB76hSR"
      },
      "source": [
        "# Find the most common letter pairs (again!)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OTmE2Axj6hWv"
      },
      "outputs": [],
      "source": [
        "token_pairs = dict()\n",
        "\n",
        "# loop over the newtext tokens (not the original!)\n",
        "for i in range(len(newtext)-1):\n",
        "\n",
        "  # create a pair\n",
        "  pair = newtext[i] + newtext[i+1]\n",
        "\n",
        "  # increase pair frequencies\n",
        "  if pair in token_pairs:\n",
        "    token_pairs[pair] += 1\n",
        "  else:\n",
        "    token_pairs[pair] = 1\n",
        "\n",
        "token_pairs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ky9njLdZUgVR"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Smkdx0MUgRx"
      },
      "source": [
        "# Now using functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DrX7ThhHcqk3"
      },
      "outputs": [],
      "source": [
        "# > -----------------------------------\n",
        "def get_pair_stats(text2pair):\n",
        "  token_pairs = dict()\n",
        "\n",
        "  # loop over tokens\n",
        "  for i in range(len(text2pair)-1):\n",
        "\n",
        "    # create a pair\n",
        "    pair = text2pair[i] + text2pair[i+1]\n",
        "\n",
        "    # increase pair frequencies\n",
        "    if pair in token_pairs:\n",
        "      token_pairs[pair] += 1\n",
        "    else:\n",
        "      token_pairs[pair] = 1\n",
        "\n",
        "  return token_pairs\n",
        "# ----------------------------------- <\n",
        "\n",
        "\n",
        "\n",
        "# > -----------------------------------\n",
        "def update_vocab(token_pairs,vocab):\n",
        "\n",
        "  # find the most frequent pair\n",
        "  idx = np.argmax(list(token_pairs.values()))\n",
        "  newtok = list(token_pairs.keys())[idx]\n",
        "\n",
        "  # update the vocab\n",
        "  vocab[newtok] = max(vocab.values())+1\n",
        "  return vocab,newtok\n",
        "# ----------------------------------- <\n",
        "\n",
        "\n",
        "\n",
        "# -----------------------------------\n",
        "def generate_new_token_seq(prevtext,newtoken):\n",
        "\n",
        "  # initialize a new text list\n",
        "  newtext = []\n",
        "\n",
        "  # loop through the list\n",
        "  i = 0\n",
        "  while i<(len(prevtext)-1):\n",
        "\n",
        "    # test whether the pair of this and the following elements match the newly-created pair\n",
        "    if (prevtext[i]+prevtext[i+1]) == newtoken:\n",
        "      newtext.append(newtoken)\n",
        "      i += 2 # skip the next character\n",
        "\n",
        "    # not a pair\n",
        "    else:\n",
        "      newtext.append(prevtext[i])\n",
        "      i += 1 # move to the next character\n",
        "\n",
        "\n",
        "\n",
        "  # the following code was missing from the video\n",
        "  if i < len(prevtext):\n",
        "    newtext.append(prevtext[i])\n",
        "\n",
        "  return newtext\n",
        "# ----------------------------------- <"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GaBv1eDocqhv"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jVnWU2qMcqe4"
      },
      "outputs": [],
      "source": [
        "# re-initialize the vocab\n",
        "vocab = { word:i for i,word in enumerate(chars) }\n",
        "print(f'Vocab has {len(vocab)} tokens.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r4vd-Pn1KjpS"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AJJoz6Y8KcPR"
      },
      "outputs": [],
      "source": [
        "## do one iteration\n",
        "\n",
        "# find and count pairs\n",
        "pairs = get_pair_stats(origtext)\n",
        "\n",
        "# update the dictionary\n",
        "vocab,newtoken = update_vocab(pairs,vocab)\n",
        "\n",
        "# get a new list of tokens\n",
        "updated_text = generate_new_token_seq(origtext,newtoken)\n",
        "print(f'Vocab has {len(vocab)} tokens.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IfVQp-FkoWmW"
      },
      "outputs": [],
      "source": [
        "updated_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "72G7ZJ1fcqbw"
      },
      "outputs": [],
      "source": [
        "## do a second iteration\n",
        "pairs = get_pair_stats(updated_text)\n",
        "\n",
        "# update the dictionary\n",
        "vocab,newtoken = update_vocab(pairs,vocab)\n",
        "\n",
        "# get a new list of tokens\n",
        "updated_text = generate_new_token_seq(updated_text,newtoken)\n",
        "print(f'Vocab has {len(vocab)} tokens.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8fzm86CAcqYY"
      },
      "outputs": [],
      "source": [
        "vocab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8zwgt0JTNw0y"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv (3.12.3)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
