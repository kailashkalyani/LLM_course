{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EmjZga3A4r5a"
      },
      "source": [
        "|<h2>Course:</h2>|<h1><a href=\"https://udemy.com/course/dullms_x/?couponCode=202508\" target=\"_blank\">A deep understanding of AI language model mechanisms</a></h1>|\n",
        "|-|:-:|\n",
        "|<h2>Part 1:</h2>|<h1>Tokenizations and embeddings<h1>|\n",
        "|<h2>Section:</h2>|<h1>Words to tokens to numbers<h1>|\n",
        "|<h2>Lecture:</h2>|<h1><b>Preparing text for tokenization<b></h1>|\n",
        "\n",
        "<br>\n",
        "\n",
        "<h5><b>Teacher:</b> Mike X Cohen, <a href=\"https://sincxpress.com\" target=\"_blank\">sincxpress.com</a></h5>\n",
        "<h5><b>Course URL:</b> <a href=\"https://udemy.com/course/dullms_x/?couponCode=202508\" target=\"_blank\">udemy.com/course/dullms_x/?couponCode=202508</a></h5>\n",
        "<i>Using the code without the course may lead to confusion or errors.</i>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "lwgCppyRKogB"
      },
      "outputs": [],
      "source": [
        "# typical libraries...\n",
        "import numpy as np\n",
        "\n",
        "# for importing and working with texts\n",
        "import requests\n",
        "import re"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eXrL9iSI4vWk"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fEFbCZ8FLEu8"
      },
      "source": [
        "# Get text from the web"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "EPRfkKgHLEsE"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'str'>\n",
            "182973\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'*** START OF THE PROJECT GUTENBERG EBOOK 35 ***\\r\\n\\r\\n\\r\\n\\r\\n\\r\\nThe Time Machine\\r\\n\\r\\nAn Invention\\r\\n\\r\\nby H. G. Wells\\r\\n\\r\\n\\r\\nCONTENTS\\r\\n\\r\\n I Introduction\\r\\n II The Machine\\r\\n III The Time Traveller Returns\\r\\n IV Time Travelling\\r\\n V In the Golden Age\\r\\n VI The Sunset of Mankind\\r\\n VII A Sudden Shock\\r\\n VIII Explanation\\r\\n IX The Morlocks\\r\\n X When Night Came\\r\\n XI The Palace of Green Porcelain\\r\\n XII In the Darkness\\r\\n XIII The Trap of the White Sphinx\\r\\n XIV The Further Vision\\r\\n XV The Time Traveller’s Return\\r\\n XVI After the Story\\r\\n Epilogue\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n I.\\r\\n Introduction\\r\\n\\r\\n\\r\\nThe Time Traveller (for so it will be convenient to speak of him) was\\r\\nexpounding a recondite matter to us. His pale grey eyes shone and\\r\\ntwinkled, and his usually pale face was flushed and animated. The fire\\r\\nburnt brightly, and the soft radiance of the incandescent lights in the\\r\\nlilies of silver caught the bubbles that flashed and passed in our\\r\\nglasses. Our chairs, being his patents, embraced and caressed us rather\\r\\nthan submitted to be sat upon, and there was that luxurious\\r\\nafter-dinner atmosphere, when thought runs gracefully free of the\\r\\ntrammels of precision. And he put it to us in this way—marking the\\r\\npoints with a lean forefinger—as we sat and lazily admired his\\r\\nearnestness over this new paradox (as we thought it) and his fecundity.\\r\\n\\r\\n“You must follow me carefully. I shall have to controvert one or two\\r\\nideas that are almost universally accepted. The geometry, for instance,\\r\\nthey taught you at school is founded on a misconception.”\\r\\n\\r\\n“Is not that rather a large thing to expect us to begin upon?” said\\r\\nFilby, an argumentative person with red hair.\\r\\n\\r\\n“I do not mean to ask you to accept anything without reasonable ground\\r\\nfor it. You will soon admit as much as I need from you. You know of\\r\\ncourse that a mathematical line, a line of thickness _nil_, has no real\\r\\nexistence. They taught you that? Neither has a mathematical plane.\\r\\nThese things are mere abstractions.”\\r\\n\\r\\n“That is all right,” said the Psychologis'"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# get raw text from internet\n",
        "book = requests.get('https://www.gutenberg.org/files/35/35-0.txt')\n",
        "\n",
        "# extract just the text and have a look at it\n",
        "text = book.text\n",
        "print(type(text))\n",
        "print(len(text))\n",
        "\n",
        "text[:2000]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "FHv-NtW2LEnI"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'*** start of the project gutenberg ebook  ***     the time machine  an invention  by h. g. wells   contents   i introduction  ii the machine  iii the time traveller returns  iv time travelling  v in the golden age  vi the sunset of mankind  vii a sudden shock  viii explanation  ix the morlocks  x when night came  xi the palace of green porcelain  xii in the darkness  xiii the trap of the white sphinx  xiv the further vision  xv the time traveller s return  xvi after the story  epilogue      i.  introduction   the time traveller (for so it will be convenient to speak of him) was expounding a recondite matter to us. his pale grey eyes shone and twinkled, and his usually pale face was flushed and animated. the fire burnt brightly, and the soft radiance of the incandescent lights in the lilies of silver caught the bubbles that flashed and passed in our glasses. our chairs, being his patents, embraced and caressed us rather than submitted to be sat upon, and there was that luxurious after-dinner atmosphere, when thought runs gracefully free of the trammels of precision. and he put it to us in this way marking the points with a lean forefinger as we sat and lazily admired his earnestness over this new paradox (as we thought it) and his fecundity.   you must follow me carefully. i shall have to controvert one or two ideas that are almost universally accepted. the geometry, for instance, they taught you at school is founded on a misconception.    is not that rather a large thing to expect us to begin upon?  said filby, an argumentative person with red hair.   i do not mean to ask you to accept anything without reasonable ground for it. you will soon admit as much as i need from you. you know of course that a mathematical line, a line of thickness  nil , has no real existence. they taught you that? neither has a mathematical plane. these things are mere abstractions.    that is all right,  said the psychologist.   nor, having only length, breadth, and thickness, can a cube h'"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# character strings to replace with space\n",
        "strings2replace = [\n",
        "                 '\\r\\n\\r\\nâ\\x80\\x9c', # new paragraph\n",
        "                 'â\\x80\\x9c',         # open quote\n",
        "                 'â\\x80\\x9d',         # close quote\n",
        "                 '\\r\\n',              # new line\n",
        "                 'â\\x80\\x94',         # hyphen\n",
        "                 'â\\x80\\x99',         # single apostrophe\n",
        "                 'â\\x80\\x98',         # single quote\n",
        "                 '_',                 # underscore, used for stressing\n",
        "                 ]\n",
        "\n",
        "# e.g., 'â\\x80\\x9d'.encode('latin1').decode('utf8')\n",
        "\n",
        "# use regular expression (re) to replace those strings with space\n",
        "for str2match in strings2replace:\n",
        "  regexp = re.compile(r'%s'%str2match)\n",
        "  text = regexp.sub(' ',text)\n",
        "\n",
        "# remove non-ASCII characters\n",
        "text = re.sub(r'[^\\x00-\\x7F]+', ' ', text)\n",
        "\n",
        "# remove numbers\n",
        "text = re.sub(r'\\d+','',text)\n",
        "\n",
        "# and make everything lower-case\n",
        "text = text.lower()\n",
        "\n",
        "# let's have a look!\n",
        "text[:2000]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WMbx-idzLEj3"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l9bZigJ-LEg4"
      },
      "source": [
        "# Parse text into words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "nuOxaaahLMh1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "['start',\n",
              " 'of',\n",
              " 'the',\n",
              " 'project',\n",
              " 'gutenberg',\n",
              " 'ebook',\n",
              " 'the',\n",
              " 'time',\n",
              " 'machine',\n",
              " 'an',\n",
              " 'invention',\n",
              " 'by',\n",
              " 'wells',\n",
              " 'contents',\n",
              " 'introduction',\n",
              " 'ii',\n",
              " 'the',\n",
              " 'machine',\n",
              " 'iii',\n",
              " 'the',\n",
              " 'time',\n",
              " 'traveller',\n",
              " 'returns',\n",
              " 'iv',\n",
              " 'time',\n",
              " 'travelling',\n",
              " 'in',\n",
              " 'the',\n",
              " 'golden',\n",
              " 'age',\n",
              " 'vi',\n",
              " 'the',\n",
              " 'sunset',\n",
              " 'of',\n",
              " 'mankind',\n",
              " 'vii',\n",
              " 'sudden',\n",
              " 'shock',\n",
              " 'viii',\n",
              " 'explanation',\n",
              " 'ix',\n",
              " 'the',\n",
              " 'morlocks',\n",
              " 'when',\n",
              " 'night',\n",
              " 'came',\n",
              " 'xi',\n",
              " 'the',\n",
              " 'palace',\n",
              " 'of']"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# split by punctuation\n",
        "import string\n",
        "print(string.punctuation)\n",
        "puncts4re = fr'[{string.punctuation}\\s]+'\n",
        "\n",
        "words = re.split(puncts4re,text)\n",
        "words = [item.strip() for item in words if item.strip()]\n",
        "\n",
        "# remove single-character words\n",
        "words = [item for item in words if len(item)>1]\n",
        "\n",
        "# let's have a look!\n",
        "words[:50]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "rnzenHKZLEZ2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "30698 words\n",
            " 4589 unique tokens\n"
          ]
        }
      ],
      "source": [
        "# create the vocab! (set of unique words)\n",
        "vocab = sorted(set(words))\n",
        "\n",
        "# convenience variables for later\n",
        "nWords = len(words)\n",
        "nLex = len(vocab)\n",
        "\n",
        "print(f'{nWords} words')\n",
        "print(f' {nLex} unique tokens')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hJIWEvEeLEW5"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x7CADnuQLET_"
      },
      "source": [
        "# Create token dictionaries and encoder/decoder functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "Belr9eoCLTcV"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "('abandon', 0)\n",
            "('aimlessly', 87)\n",
            "('apologise', 174)\n",
            "('attained', 261)\n",
            "('behaved', 348)\n",
            "('both', 435)\n",
            "('can', 522)\n",
            "('cheerfully', 609)\n",
            "('coat', 696)\n",
            "('contents', 783)\n",
            "('culminating', 870)\n",
            "('delay', 957)\n",
            "('dimness', 1044)\n",
            "('dragging', 1131)\n",
            "('edition', 1218)\n",
            "('everywhere', 1305)\n",
            "('facilities', 1392)\n",
            "('find', 1479)\n",
            "('footfall', 1566)\n",
            "('furnishing', 1653)\n",
            "('gold', 1740)\n",
            "('hallo', 1827)\n",
            "('high', 1914)\n",
            "('ideas', 2001)\n",
            "('inextinguishable', 2088)\n",
            "('invest', 2175)\n",
            "('lamp', 2262)\n",
            "('likewise', 2349)\n",
            "('manhood', 2436)\n",
            "('minerals', 2523)\n",
            "('mysteries', 2610)\n",
            "('novelty', 2697)\n",
            "('outbreaks', 2784)\n",
            "('paws', 2871)\n",
            "('plato', 2958)\n",
            "('previously', 3045)\n",
            "('questionings', 3132)\n",
            "('reflecting', 3219)\n",
            "('return', 3306)\n",
            "('sandals', 3393)\n",
            "('senses', 3480)\n",
            "('shrinking', 3567)\n",
            "('slit', 3654)\n",
            "('special', 3741)\n",
            "('stick', 3828)\n",
            "('sudden', 3915)\n",
            "('tap', 4002)\n",
            "('thrice', 4089)\n",
            "('treat', 4176)\n",
            "('unfrozen', 4263)\n",
            "('vertical', 4350)\n",
            "('wearisome', 4437)\n",
            "('wonderful', 4524)\n"
          ]
        }
      ],
      "source": [
        "word2idx = {w:i for i,w in enumerate(vocab)}\n",
        "idx2word = {i:w for i,w in enumerate(vocab)}\n",
        "\n",
        "# print out a few\n",
        "for i in list(word2idx.items())[0:10000:87]:\n",
        "  print(i)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "esuSuaEgLERc"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "2HYTeIawLEOk"
      },
      "outputs": [],
      "source": [
        "# encoder function (using for-loop instead of list-comp)\n",
        "def encoder(words,encode_dict):\n",
        "\n",
        "  # initialize a vector of numerical indices\n",
        "  idxs = np.zeros(len(words),dtype=int)\n",
        "\n",
        "  # loop through the words and find their token in the vocab\n",
        "  for i,w in enumerate(words):\n",
        "    idxs[i] = encode_dict[w]\n",
        "\n",
        "  # return the indices!\n",
        "  return idxs\n",
        "\n",
        "\n",
        "# also need a decoder function\n",
        "def decoder(idxs,decode_dict):\n",
        "  return ' '.join([decode_dict[i] for i in idxs])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "93yoreY15Y-u"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[4042 4109 2416]\n",
            "abandoned abnormally absent\n"
          ]
        }
      ],
      "source": [
        "# test the encoder\n",
        "print(encoder(['the','time','machine'],word2idx))\n",
        "\n",
        "# test the decoder\n",
        "print(decoder([1,3,10],idx2word))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c7jgPRj_cRAj"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "nsJOMwjKaNpp"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Word indices:\n",
            "[22017 22018 22019 22020 22021 22022 22023 22024 22025 22026]\n",
            "\n",
            "The words:\n",
            "['of', 'the', 'gallery', 'sloped', 'at', 'all', 'footnote', 'it', 'may', 'be']\n",
            "\n",
            "Token indices:\n",
            "[2731 4042 1663 3656  255   96 1568 2186 2468  319]\n",
            "\n",
            "Decoded text from indices:\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'of the gallery sloped at all footnote it may be'"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# test encode-then-decode\n",
        "\n",
        "# random start location\n",
        "startidx = np.random.choice(nWords)\n",
        "\n",
        "# sequential word indices\n",
        "idxs = np.arange(startidx,startidx+10)\n",
        "\n",
        "print('Word indices:')\n",
        "print(idxs), print('')\n",
        "\n",
        "print('The words:')\n",
        "wordseq = [ words[i] for i in idxs ]\n",
        "print(wordseq), print('')\n",
        "\n",
        "print('Token indices:')\n",
        "tokenseq = encoder(wordseq,word2idx)\n",
        "print(tokenseq), print('')\n",
        "\n",
        "# decode\n",
        "print('Decoded text from indices:')\n",
        "decoder(tokenseq,idx2word)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "od2XevtsY3G9"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv (3.12.3)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
